# Introdu√ß√£o

- **Teoria Estat√≠stica**: objetiva obter uma infer√™ncia sobre a distribui√ß√£o de probabilidade de um fen√¥meno a partir de observa√ß√µes. 

- A base te√≥rica do livro *The Bayesian Choice* √© constru√≠da sob o ponto de vista da Teoria da Decis√£o. Isso se deve a dois fatores: $(I)$ a infer√™ncia tem algum objetivo, isto √©, alguma decis√£o √© tomada baseada em uma previs√£o ou an√°lise, e ela tem consequ√™ncias mensur√°veis; e $(II)$ a decis√£o clarifica a prefer√™ncia do estat√≠stico.

- Estat√≠stica √© mais sobre a interpreta√ß√£o de fen√¥menos naturais do que a explica√ß√£o sobre eles. Al√©m disso, ela tem um passo de *formaliza√ß√£o redutiva*. 

- A modelagem estat√≠stica, atrav√©s probabilidade, possibilita incluir a informa√ß√£o dispon√≠vel sobre o fen√¥meno e a incerteza sobre essa informa√ß√£o. Uma cr√≠tica √† abordagem probabil√≠stica √© a dificuldade em saber exatamente a distribui√ß√£o de probabilidade do fen√¥meno. 

---
``üìù`` **Exemplo (modelo capture-recapture)**

Suponha que queremos estimar o n√∫mero de √¥nibus $N$ em uma cidade. Uma forma de fazer isso √© a seguinte: contamos a quantidade vista de √¥nibus em um dia ($q_1$) e armazenamos a identifica√ß√£o de cada um. No dia seguinte, fazemos a mesma coisa e obtemos ($q_2$). Seja $n$ o n√∫mero de √¥nibus que vimos nos dois dias. Qual a distribui√ß√£o de $n$? Olhando para o segundo dia, em uma popula√ß√£o de tamanho $N$, t√≠nhamos $q_1$ √¥nibus de interesse para recontar. Nossa amostra √© de tamanho $q_2$. Isso define a [distribui√ß√£o hipergeom√©trica](https://en.wikipedia.org/wiki/Hypergeometric_distribution), pois a amostragem do segundo dia √© sem reposi√ß√£o (note que simplificamos que s√≥ podemos ver o mesmo √¥nibus uma vez). Logo

$$n \sim Hypergeometric(N, q_1, q_2).$$

Sabemos que $\mathbb{E}[n] = (q_1/N) \cdot q_2 \implies \hat{N} = q_1 \cdot q_2 / n$ √© um poss√≠vel estimador para $N$. Note que esse estimador n√£o √© necessariamente n√£o enviesado, pois $\mathbb{E}[1/n] \neq 1/\mathbb{E}[n]$.

---

- Para aproximar uma distribui√ß√£o de probabilidade de um fen√¥meno, duas abordagens estat√≠sticas s√£o usadas: **n√£o param√©trica** e **param√©trica**. Na primeira, a estimativa procura assumir o m√≠nimo de hip√≥teses poss√≠vel, procurando uma estima√ß√£o funcional. J√° a segunda vem de uma densidade parametrizada, em que o par√¢metro de dimens√£o finita √© desconhecido.

- Um modelo estat√≠stico param√©trico consiste de observa√ß√µes de uma vari√°vel aleat√≥ria $x \in \mathcal{X}$ (espa√ßo de estados) com distribui√ß√£o cuja densidade √© $f(x | \theta)$ e $\theta \in \Omega$ (espa√ßo dos par√¢metros) √© desconhecido com dimens√£o finita. 

- Logo, m√©todos estat√≠sticos permitem fazer infer√™ncia sobre $\theta$ a partir de $x$, enquanto a modelagem probabil√≠stica caracteriza o comportamento de observa√ß√µes futuras condicionadas em $\theta$. 

## Modelo param√©trico 

Schervish apresenta uma defini√ß√£o formalizada de modelo param√©trico, a qual eu apresento a seguir. 

> Seja $(S, \mathcal{A}, \mu)$ um espa√ßo de probabilidade, e $(\mathcal{X}, \mathcal{B})$ e $(\Omega, \tau)$ espa√ßos de Borel (espa√ßo mensur√°vel isomorfo a um subconjunto mensur√°vel dos reais. Em geral, veremos que esses espa√ßos s√£o subconjuntos mensur√°veis dos reais). Seja $X : S \to \mathcal{X}$ e $\Theta : S \to \Omega$ fun√ß√µes mensur√°veis. Chamamos $\Theta$ de par√¢metro e $\Omega$ de espa√ßo de par√¢metros. A distribui√ß√£o de $X | \Theta = \theta$ √© fam√≠lia param√©trica de distribui√ß√µes de $X$ dada por $P_{\theta}$. A medida de probabilidade $\mu_{\Theta}$ sobre $(\Omega, \tau)$ induzida por $\Theta$ a partir de $\mu$ √© chamada de distribui√ß√£o a priori ($\mu_{\Theta}(B) = \mu(\Theta \in B), B \in \tau$). A densidade de $P_{\theta}$ (que √© absolutamente cont√≠nua) com respeito √† uma medida $\nu$ √© dada por
> $$f_{X|\Theta}(x|\theta) = \frac{dP_{\theta}}{d\nu}(x),$$
> a derivada de Radon-Nikodym. 

## Paradigma bayesiano

No paradigma bayesiano, as quantidades desconhecidas s√£o tratadas como vari√°veis aleat√≥rias, incluindo o par√¢metro $\theta$. Na p√°gina 12 de seu livro, Shervish apresenta uma justificativa matem√°tica para esse fato. Assim, se temos um modelo $P_{\theta}$ para $x$, precisamos de uma distribui√ß√£o para $\theta$, a qual chamamos de **distribui√ß√£o a priori**. Com elas, constru√≠mos uma distribui√ß√£o em $\mathcal{X} \times \Omega$. Em particular, 

$$\Pr((x,\theta) \in B) = \int_{\Omega} \int_{\mathcal{X}} I_B(u, v) f_{x | \theta}(u|v)f_{\theta}(v) \, du \, dv,$$

se $f_{\theta}$ for a densidade da distribui√ß√£o de $\theta$. Para isso, basta exigir que $f_{X | \Theta}$ seja mensur√°vel em $\mathcal{B} \otimes \tau$.Matematicamente, probabilidades podem representar cren√ßas numericamente, relacionando informa√ß√£o com probabilidade. A Regra de Bayes prov√™ um m√©todo racional para atualizar essas cren√ßas frente a novas informa√ß√µes. O processo indutivo de atualizar cren√ßas com Bayes √© chamada de infer√™ncia bayesiana. 

### Teorema de Bayes

Se $E$ √© um evento com probabilidade positiva e $A$ √© um outro evento, temos que 
$$\Pr(A | E) = \frac{\Pr(E |A) \Pr(A)}{\Pr(E)}.$$
Podemos expressar atrav√©s de densidades, com 
$$p(\theta | x) = \frac{f(x|\theta)\pi(\theta)}{\int_{\Omega} f(x|t)\pi(t) \, dt},$$
em que $\pi(\theta)$ √© a densidade da priori do par√¢metro $\theta$ e $p(\theta | x)$ √© chamada de **distribui√ß√£o a posteriori** de $\theta$ (para uma demonstra√ß√£o detalhada do Teorema de Bayes, vale conferir a p√°gina 16 do livro de Schervish). Al√©m disso, como o par√¢metro $\theta$ √© desconhecido, tamb√©m denotamos a densidade de $x$ condicionada em $\theta$ como uma fun√ß√£o de $\theta$, ap√≥s observar $x$. Nesse caso, chamamos de **fun√ß√£o de verossimilhan√ßa** $l(\theta | x) = f(x | \theta)$ para cada $\theta \in \Omega$ e $x$ observado. O denominador da express√£o acima √© chamada de **densidade preditiva a priori** e n√£o depende de $\theta$. √â a marginal no espa√ßo de estados. 

A distribui√ß√£o a priori encapsula a informa√ß√£o dispon√≠vel sobre o par√¢metro $\theta$ antes do experimento, incluindo a incerteza residual. Se a distribui√ß√£o a priori e a distribui√ß√£o dos dados representam cren√ßas racionais, [a regra de Bayes √© o m√©todo √≥timo para atualizar essas cren√ßas](https://books.google.com.br/books?id=V8jT2SimGR0C&pg=PA2&lpg=PA2&dq=%22Bayes%E2%80%99+rule+is+an+optimal+method%22&source=bl&ots=X6NYVjaGMG&sig=ACfU3U35KV7iPBPmwMc8lNcupnc5zrEysg&hl=en&sa=X&ved=2ahUKEwiH7PmO0uT2AhWQVt8KHTpsBCgQ6AF6BAgcEAM#v=onepage&q=%22Bayes%E2%80%99%20rule%20is%20an%20optimal%20method%22&f=false) sobre o par√¢metro dada nova informa√ß√£o. Claro que, em geral, n√£o conseguimos explorar as cren√ßas de modo perfeito e a posteriori n√£o vai ser √≥tima, nesse sentido. 

---
``üìù`` **Exemplo (Bayes, 1974)**

Uma bola de sinuca $O$ √© rolada em uma linha de comprimento 1. √â natural assumir que ela tem uma distribui√ß√£o uniforme de parar em qualquer lugar, s√≥ dependendo da for√ßa exercida sobre ela. Seja $p$ o ponto de parada. Em seguida, rolamos uma outra bola $n$ vezes e contamos a quantidade de vezes ($X$) que ela parou antes de $B$. Nesse caso, observado $X=x$, queremos inferir $p$. Se $p$ fosse conhecido, qual seria distribui√ß√£o de $X$? Veja que temos $n$ experimentos independentes e id√™nticos de sucesso ou falha, com probabilidade de sucesso $p$ (lembrando da distribui√ß√£o uniforme!). Nesse caso $X|p \sim Bernoulli(n, p)$. Com essas configura√ß√µes, podemos verificar que 
$$\Pr(a < p < b | X=x) = \frac{\int_a^b p^x(1-p)^{n-x} \, dp}{B(x+1, n-x+1)},$$
em que $B$ √© a [fun√ß√£o Beta](https://en.wikipedia.org/wiki/Beta_function).

---

Enquanto a estat√≠stica cl√°ssica √© dirigida por princ√≠pios justificados axiomaticamente, a abordagem bayesiana incorpora esses princ√≠pios sem a restri√ß√£o sobre os procedimentos e tamb√©m rejeita outros princ√≠pios. Por exemplo, o conceito de estimadores n√£o enviesados, em geral preferidos na estat√≠stica cl√°ssica, imp√µe restri√ß√µes fortes sobre os procedimentos adotados e leva a performances ineficientes (ver [exemplo de Stein](https://en.wikipedia.org/wiki/Stein%27s_example)). Isso acontece, pois a justificativa √© assint√≥tica, j√° que em m√©dia o estimador √© correto. 

Por fim, em estat√≠stica bayesiana, **TODAS AS INFER√äNCIAS S√ÉO BASEADAS NA DISTRIBUI√á√ÉO A POSTERIORI**.

## Um pouco de hist√≥ria

Em 1763, √© publicado [An Essay towards Solving a Problem in the Doctrine of Chances](https://www.jstor.org/stable/105741?seq=1), paper atribu√≠do a Thomas Bayes e publicado por Richard Price. O principal objeto desse trabalho, al√©m do exemplo acima, √© o que conhecemos como Teorema de Bayes, mas com a priori sendo uniforme. Laplace, em [Memoir on the Probability of the Causes of Events](https://www.york.ac.uk/depts/maths/histstat/memoir1774.pdf) foi quem descreveu em uma forma mais geral, apesar de ainda ser discreta. Do ponto de vista probabil√≠stico, o Teorema de Bayes √© apenas uma forma de mensurar a incerteza. A controv√©rsia adv√©m da interpreta√ß√£o da probabilidade e se ele deveria ser considerado ponto central no processo de aprendizado. 

## Vis√£o subjetiva da probabilidade

A vis√£o de que o mundo √© determin√≠stico ou n√£o, como a discuss√£o do [Dem√¥nio de Laplace](https://en.wikipedia.org/wiki/Laplace%27s_demon), √© pouco importante na verdade para a estat√≠stica. O que importa √© a incerteza que temos sobre as quantidades. No pref√°cio de seu livro [Theory of Probability](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119286387.fmatter), Bruno de Finetti argumenta que "probabilidade n√£o existe" no sentido *objetivo*. A √∫nica exig√™ncia √© que exista consist√™ncia em nossas cren√ßas e na rela√ß√£o com dados objetivos. Basicamente, a defini√ß√£o de probabilidade √© subjetiva: a taxa em que o indiv√≠duo est√° disposto a apostar na ocorr√™ncia de um evento.

Considere um dado normal de seis lados. Um frequentista afirmaria que, por simetria, cada lado tem igual chance de ocorrer. Evid√™ncia emp√≠rica passada suportaria sua afirma√ß√£o. Um subjetivista ouviria os argumentos, mas o que realmente iria considerar seria sua cren√ßa sobre o que acontecer√° em uma jogada de dados, isto √©, quanto seria apostado em cada lado, dada a informa√ß√£o presente. Logo, no trabalho de De Finetti, Probabilidade e Pre√ßo s√£o equivalentes. Para uma discuss√£o mais detalhada, consulte [esse trabalho](https://faculty.fuqua.duke.edu/~rnau/definettiwasright.pdf).

## Princ√≠pio da Verossimilhan√ßa e Princ√≠pio da Sufici√™ncia

### Sufici√™ncia

Seja $x \sim f(x | \theta)$. Uma fun√ß√£o/estat√≠stica $T: \mathcal{X} \to \mathbb{R}^k$ (a imagem de $T$, juntamente com o conjunto de seus singletons, pode ser qualquer espa√ßo mensur√°vel) √© **suficiente** se a distribui√ß√£o de $x$ condicionada em $T(x)$ n√£o depende de $\theta$. Para mais detalhes, ver [aqui](/ta-sessions/infestatistica/SufficientStatistics/). De forma simplificada, $T(x)$ traz toda a informa√ß√£o sobre $\theta$ advinda de $x$. Schervish (p√°gina 84) adiciona o fato de que para qualquer priori $\pi(theta)$, a distribui√ß√£o a posteriori de $\theta$ condicionada em $x$ e a posteriori condicionada em $T(x)$ s√£o iguais quase certamente. Como demonstrado no Teorema 2.14 do mesmo livro, essas defini√ß√µes s√£o equivalentes dadas algumas hip√≥teses de regularidade.

O **Teorema da fatora√ß√£o Fisher-Neyman** mostra que se a densidade de $x$ √© a derivada de Radon-Nikodym para alguma medida de probabilidade ($\sigma$ - finita) cuja distribui√ß√£o seja absolutamente cont√≠nua, ent√£o vale que $T(x)$ √© suficiente para $\theta$ se, e somente se, existem fun√ß√µes $g$ e $h$ n√£o-negativas tal que 

$$f(x|\theta) = g(T(x)|\theta)h(x|T(x)).$$

O conceito de sufici√™ncia foi introduzido por Fisher e est√° associado com o seguinte princ√≠pio:

> **Princ√≠pio da Sufici√™ncia (PS):** Se duas observa√ß√µes $x$ e $y$ s√£o tais que $T(x) = T(y)$ para alguma estat√≠stica suficiente $T$, ent√£o elas devem levar √† mesma infer√™ncia sobre o par√¢metro.

---
``üìù`` **Exemplo**

Suponha que observamos $x = (x_1, \dots, x_n) \overset{iid}{\sim} Exponential(\lambda)$. Uma estat√≠stica suficiente para $\lambda$ √© a m√©dia amostral $T(x) = \bar{x}$, em particular, 
$$f(x | \lambda) = \lambda^n e^{-\lambda n \bar{x}}.$$
Logo, infer√™ncias sobre $\lambda$ s√≥ devem se basear em $\bar{x}$, segundo o Princ√≠pio da sufici√™ncia.

---

### Princ√≠pio da Verossimilhan√ßa 

Esse conceito √© tamb√©m atribu√≠do a [Fisher](https://www.amazon.com/Statistical-Methods-Scientific-Inference-Ronald/dp/0050008706), mas a sua formaliza√ß√£o se deve a [Birnbaum (1962)](https://www.jstor.org/stable/pdf/2281640.pdf).

> **Princ√≠pio da Verossimilhan√ßa (PV):** a informa√ß√£o trazida por uma observa√ß√£o $x$ sobre $\theta$ √© inteiramente contida na fun√ß√£o de verossimilhan√ßa $l(\theta|x)$. Al√©m do mais, se duas observa√ß√µes $x$ e $y$ dependem de $\theta$, de forma que $l_1(\theta|x) = cl_2(\theta|y), \, \forall \theta \in \Omega$ para alguma constante $c$, ent√£o elas levam √† mesma infer√™ncia sobre $\theta$. 

Uma outra forma de expressar esse princ√≠pio √© o seguinte: Se $E$ e $E'$ s√£o experimentos definidos em $\Omega$, representados pelas densidades $f(x, \theta)$ e $g(y, \theta)$, e $x$ e $y$ s√£o observa√ß√µes determinando a mesma fun√ß√£o de verossimilhan√ßa, ent√£o a evid√™ncia trazida por ambos os experimentos √© a mesma vista a partir dessas observa√ß√µes, isto √©, o resultado $x$ de qualquer experimento $E$ √© caracterizado somente pela verossimilhan√ßa at√© uma constante. 

---
``üìù`` **Exemplo**

Seja $\theta \in [0,1]$ a propor√ß√£o de doentes em uma popula√ß√£o. Um examinador encontrou nove pessoas saud√°veis e tr√™s doentes. Se nenhuma informa√ß√£o adicional √© obtida, podemos propor dois modelos diferentes para esse fen√¥meno:

(1) O examinador testou 12 pessoas e observou $x \sim Binomial(12, \theta)$ com $x = 3$.

(2) Ele questionou $N = 12$ pessoas at√© encontrar $3$ doentes. Nesse caso, $N \sim NegativeBinomial(3, \theta)$

Apesar do dado ser diferente em ambos os experimentos, as verossimilhan√ßas s√£o proporcionais. Portanto, as infer√™ncias devem ser as mesmas sobre $\theta$.

---

Como as infer√™ncias s√£o baseadas na posteriori, a abordagem bayesiana satisfaz o Princ√≠pio da Verossimilhan√ßa. Por√©m, na abordagem frequentista, isso n√£o √© verdade, j√° que √© baseada no comportamento m√©dio dos procedimentos. O estimador de m√°xima verossimilhan√ßa tamb√©m satisfaz.

### Derivando o princ√≠pio da verossimilhan√ßa

> **Princ√≠pio da Condicionalidade (PC):** Se dois experimentos $E$ e $E'$ sobre $\Omega$ est√£o dispon√≠veis e um deles √© selecionado com probabilidade $p$, a infer√™ncia resultante sobre $\theta$ s√≥ deveria depender do experimento selecionado.
 
O fato que Birnbaum demonstrou √© que PS + PC = PL. Isso √© interessante, pois, para muitos estat√≠sticos, PS e PC s√£o aceit√°veis, mais PL n√£o. Isso faz com que os resultados cient√≠ficos, para serem coerentes, devessem ser descritos atrav√©s da fun√ß√£o de verossimilhan√ßa, e n√£o por n√≠veis de signific√¢ncia e estimativas intervalares. [Evans, 2013](https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-7/issue-none/What-does-the-proof-of-Birnbaums-theorem-prove/10.1214/13-EJS857.full) utiliza teoria dos conjuntos para mostrar que a demonstra√ß√£o de Birnbaum tem falhas, j√° que ignora uma hip√≥tese chave. [Gandenberger, 2015](https://www.journals.uchicago.edu/doi/abs/10.1093/bjps/axt039?journalCode=bjps) ofereceu uma nova demonstra√ß√£o para o Princ√≠pio da Verossimilhan√ßa, mas com hip√≥teses diferentes. [Aqui](https://vicpena.github.io/isba2016.pdf) temos um breve resumo em formato de slides.

## Distribui√ß√µes a priori e a posteriori

Dada a distribui√ß√£o de $x$ dada por $f(x|\theta)$ e a distribui√ß√£o a priori $\pi(\theta)$, podemos derivar as seguintes distribui√ß√µes:

(a) a distribui√ß√£o conjunta
$$ \varphi(x, \theta) = f(x |\theta) \pi(\theta);$$

(b) a distribui√ß√£o marginal de $x$
$$m(x) = \int f(x|\theta) \pi(\theta) \, d\theta;$$

(c) a distribui√ß√£o a posteriori de $\theta$
$$p(\theta|x) = \frac{f(x|\theta)\pi(\theta)}{m(x)};$$

(d) a distribui√ß√£o preditiva de $y$, quando $y \sim g(y|x, \theta),$
$$g(y|x) = \int g(y|\theta, x) \pi(\theta | x) \, d\theta.$$

### Distribui√ß√µes a priori impr√≥prias

Para a especifica√ß√£o de um modelo (param√©trico) segundo o preceito bayesiano, √© preciso definir uma fam√≠lia param√©trica para as observa√ß√µes $X$ e uma distribui√ß√£o a priori para $\theta$. √â importante destacar que ambas s√£o escolhas que introduzem subjetividade. Para especificar uma priori, traduzimos conhecimento pr√©vio em uma distribui√ß√£o de probabilidade. Nem sempre, temos uma informa√ß√£o suficiente para tal. Uma maneira usual de contornar essa situa√ß√£o √© construir uma sequ√™ncia de distribui√ß√µes no espa√ßo de par√¢metros e tomar $\pi$ como a distribui√ß√£o limite. Todavia, ela poder√° sofrer com a propriedade que 
$$ \int_{\Omega} \pi(\theta) \, d\theta = + \infty.$$
Nesse caso temos uma **distribui√ß√£o impr√≥pria** ou generalizada. 

