# Introdu√ß√£o

- **Teoria Estat√≠stica**: objetiva obter uma infer√™ncia sobre a distribui√ß√£o de probabilidade de um fen√¥meno a partir de observa√ß√µes. 

- A base te√≥rica do livro *The Bayesian Choice* √© constru√≠da sob o ponto de vista da Teoria da Decis√£o. Isso se deve a dois fatos: (i) a infer√™ncia tem algum objetivo, isto √©, alguma decis√£o deve ser tomada baseada em uma previs√£o ou an√°lise, e ela tem consequ√™ncias mensur√°veis; e (ii) a decis√£o clarifica a prefer√™ncia do estat√≠stico.

- Estat√≠stica √© mais sobre a interpreta√ß√£o de fen√¥menos naturais do que a explica√ß√£o sobre eles. Ela tem um passo de *formalica√ß√£o redutiva*. 

- A modelagem estat√≠tica atrav√©s probabilidade possibilita incluir informa√ß√£o dispon√≠vel sobre o fen√¥meno e a incerteza sobre essa informa√ß√£o. Uma cr√≠tica √† abordagem probabil√≠stica √© a dificuldade em saber a distribui√ß√£o de probabilidade do fen√¥meno exatamente. 

---
``üìù`` **Exemplo (modelo capture-recapture)**

Suponha que queremos estimar o n√∫mero de √¥nibus $N$ em uma cidade. Uma forma de fazer isso √© a seguinte: contamos a quantidade vista de √¥nibus em um dia ($q_1$) e armazenamos a identifica√ß√£o de cada um. No dia seguinte, fazemos a mesma coisa e obtemos ($q_2$). Seja $n$ o n√∫mero de √¥nibus que vimos nos dois dias. Qual a distribui√ß√£o de $n$? Olhando para o segundo dia, em uma popula√ß√£o de tamanho $N$, t√≠nhamos $q_1$ √¥nibus de interesse para recontar. Nossa amostra √© de tamanho $q_2$. Isso define a [distribui√ß√£o hipergeom√©trica](https://en.wikipedia.org/wiki/Hypergeometric_distribution), pois a amostragem do segundo dia √© sem reposi√ß√£o (note que simplificamos que s√≥ podemos ver o mesmo √¥nibus uma vez). Logo

$$n \sim Hypergeometric(N, q_1, q_2).$$

Sabemos que $\mathbb{E}[n] = (q_1/N) \cdot q_2 \implies \hat{N} = q_1 \cdot q_2 / n$ √© um poss√≠vel estimador para $N$. Note que esse estimador n√£o √© necessariamente n√£o enviesado, pois $\mathbb{E}[1/n] \neq 1/\mathbb{E}[n]$.

---

- Para aproximar uma distribui√ß√£o de probabilidade de um fen√¥meno, duas abordagens estat√≠ticas s√£o usadas: **n√£o param√©trica** e **param√©trica**. Na primeira, a estimativa procura assumir o m√≠nimo poss√≠vel, procurando uma estima√ß√£o funcional. J√° a segunda, representa atrav√©s de uma densidade parametrizada, em que o par√¢metro de dimens√£o finita √© desconhecido.

- Um modelo estat√≠stico param√©trico consiste de observa√ß√µes de uma vari√°vel aleat√≥ria $x \in \mathcal{}$ (espa√ßo de estados) com distribui√ß√£o cuja densidade √© $f(x | \theta)$ e $\theta \in \Omega$ (espa√ßo dos par√¢metros) √© desconhecido com dimens√£o finita. 

- Logo, m√©todos estat√≠sticos permitem fazer infer√™ncia sobre $\theta$ a partir de $x$, enquanto a modelagem probabil√≠stica caracteriza o comportamento de observa√ß√µes futuras condicionadas em $\theta$. 

## Paradigma bayesiano

No paradigma bayesiano, as quantidades desconhecidas s√£o tratadas como vari√°vel aleat√≥ria, incluindo o par√¢metro $\theta$. Assim, se temos um modelo $P_{\theta}$ para $x$, precisamos de uma distribui√ß√£o para $\theta$, a qual chamamos de **distribui√ß√£o a priori**. Com elas, constru√≠mos uma distribui√ß√£o em $\mathcal{X} \times \Omega$. Em particular, 

$$\Pr((x,\theta) \in B) = \int_{\Omega} \int_{\mathcal{X}} I_B(u, v) f_{x | \theta}(u|v)f_{\theta}(v) \, du \, dv,$$

se $f_{\theta}$ for a densidade da distribui√ß√£o de $\theta$. 

Matematicamente, probabilidades podem representar cren√ßas numericamente, relacionando informa√ß√£o com probabilidade. A Regra de Bayes prov√™ um m√©todo racional para atualizar cren√ßas frente a novas informa√ß√µes. O processo indutivo de atualizar cren√ßas com Bayes √© chamada de infer√™ncia bayesiana. 

### Teorema de Bayes

Se $E$ √© um evento com probabilidade positiva e $A$ √© um outro evento, temos que 
$$\Pr(A | E) = \frac{\Pr(E |A) \Pr(A)}{\Pr(E)}.$$
Podemos expressar atrav√©s de densidades, com 
$$p(\theta | x) = \frac{f(x|\theta)\pi(\theta)}{\int_{\Omega} f(x|t)\pi(t) \, dt},$$
em que $\pi(\theta)$ √© a densidade da priori do par√¢metro $\theta$ e $p(\theta | x)$ √© chamada de **distribui√ß√£o a posteriori** de $\theta$. Al√©m disso, como o par√¢metro $\theta$ √© desconhecido, tamb√©m denotamos a densidade de $x$ condicionada em $\theta$ como uma fun√ß√£o de $\theta$, ap√≥s observar $x$. Nesse caso, chamamos de **fun√ß√£o de verossimilhan√ßa** $l(\theta | x) = f(x | \theta)$ para cada $\theta \in \Omega$ e $x$ observado. O denominador da express√£o acima √© chamada de **densidade preditiva a priori** e n√£o depende de $\theta$. √â a marginal no espa√ßo de estados.

A distribui√ß√£o a priori encapsula a informa√ß√£o dispon√≠vel sobre o par√¢metro $\theta$ antes do experimento, incluindo a incerteza residual. Cox (1946, 1961) and Savage (1954, 1972) provaram que se priori e verossimilhan√ßa representam cren√ßas racionais, a regra de Bayes √© o m√©todo √≥timo de atualizar essas cren√ßas sobre o par√¢metro dada nova informa√ß√£o. Claro que, em geral, n√£o conseguimos exploxar as cren√ßas de modo perfeito e a posteriori n√£o vai ser √≥tima, nesse sentido. 

---
``üìù`` **Exemplo (Bayes, 1974)**

Uma bola de sinuca $O$ √© rolada em uma linha de comprimento 1. √â natural assumir que ela tem uma distribui√ß√£o uniforme de parar em qualquer lugar, s√≥ dependendo da for√ßa exercida sobre ela. Seja $p$ o ponto de parada. Em seguida, rolamos uma outra bola $n$ vezes e contamos a quantidade de vezes ($X$) que ela parou antes de $B$. Nesse caso, observado $X=x$, queremos inferir $p$. Se $p$ fosse conhecido, qual seria distribui√ß√£o de $X$? Veja que temos $n$ experimentos independentes e id√™nticos de sucesso ou falha, com probabilidade de sucesso $p$ (lembrando da distribui√ß√£o uniforme!). Nesse caso $X|p \sim Bernoulli(n, p)$. Com essas configura√ß√µes, podemos verificar que 
$$\Pr(a < p < b | X=x) = \frac{\int_a^b p^x(1-p)^{n-x} \, dp}{B(x+1, n-x+1)},$$
em que $B$ √© a [fun√ß√£o Beta](https://en.wikipedia.org/wiki/Beta_function).

---

Enquanto a estat√≠stica cl√°ssica √© dirigida por princ√≠pios justificados axiomaticamente, a abordagem bayesiana incorpora esses princ√≠pios sem a restri√ß√£o sobre os procedimentos e tamb√©m rejeita outros pinc√≠pios. Por exemplo, o conceito de estimadores n√£o enviesados, em geral preferidos na estat√≠stica cl√°ssica, imp√µe restri√ß√µes fortes sobre os procedimentos adotados e leva a performances ineficientes (ver [exemplo de Stein](https://en.wikipedia.org/wiki/Stein%27s_example)). Isso acontece, pois a justificativa √© assint√≥tica, j√° que em m√©dia o estimador √© correto. 

## Princ√≠pio da Verossimilhan√ßa e Princ√≠pio da Sufici√™ncia

### Sufici√™ncia

Se $x \sim f(x | \theta)$, uma fun√ß√£o $T: \mathcal{X} \to \mathbb{R}^k$ (estat√≠stica) √© **suficiente** se a distribui√ß√£o de $x$ condicionada em $T(x)$ n√£o depende em $\theta$. Para mais detalhes, ver [aqui](/ta-sessions/infestatistica/SufficientStatistics/). De forma simplificada, $T(x)$ traz toda a informa√ß√£o sobre $\theta$ advinda de $x$.

