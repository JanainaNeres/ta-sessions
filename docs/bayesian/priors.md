# Distribui√ß√µes a priori

A determina√ß√£o da distribui√ß√£o a priori para a quantidade de interesse √© um ponto-chave da infer√™ncia bayesiana e, simultaneamente, √© alvo de cr√≠ticas. 
De forma geral, queremos codificar a informa√ß√£o sobre um par√¢metro $\theta$ antes de realizarmos um determinado experimento. 
Dessa forma, a partir de uma informa√ß√£o a priori, queremos definir uma distribui√ß√£o a priori. 
√â claro que raramente conseguimos fazer esse processo de forma exata e √∫nica. 
Quando a informa√ß√£o √© insuficiente para definir uma distribui√ß√£o de probabilidade, o estat√≠stico deve colocar informa√ß√£o subjetiva para, ent√£o, obter uma priori que fa√ßa sentido.
Como a distribui√ß√£o a priori influencia as infer√™ncias a posteriori o tanto quanto se queira (no limite, podemos colocar a massa de probabilidade em um √∫nico ponto), an√°lises de robustez e de sensibilidade s√£o essenciais no dia-a-dia bayesiano.

## Determina√ß√£o de uma priori

Queremos que a priori $\pi$ resuma a informa√ß√£o dispon√≠vel sobre o fen√¥meno e a incerteza que temos sobre essa informa√ß√£o, mesmo quando $\theta$ n√£o adv√©m de um processo aleat√≥rio.
Usando o conceito de George Box de que [todos os modelos s√£o errados](https://en.wikipedia.org/wiki/All_models_are_wrong), n√£o existe uma priori verdadeira e, portanto, buscamos aproxima√ß√µes para representar $\pi$.

---
``üìù`` **Exemplo (Distribui√ß√£o normal)**

Suponha que observamos $x_1, \dots, x_n \sim N(\theta, 1)$ e assumimos que $\theta \sim N(\mu, \tau)$. A m√©dia a posteriori de $\theta$ √© dada por 
$$
\mathbb{E}[\theta|x] = \frac{\bar{x}\tau + \mu/n}{\tau + 1/n}. 
$$
Nesse caso, note que estamos fazendo uma m√©dia ponderada de $\bar{x}$ e $\mu$ com pesos $\tau$ e $1/n$, respectivamente. Dessa forma, poder√≠amos pensar que a priori, ter√≠amos virtualmente uma amostra de tamanho $\tau^{-1}$ e m√©dia $\mu$. 

---

Podemos construir uma medida de probabilidade para $\theta$ atrav√©s de uma rela√ß√£o $\preceq$ que ordena o qu√£o prov√°vel √© um evento definido pela vari√°vel aleat√≥ria $\theta$, como resumido [aqui](https://lucasmoschen.github.io/files/disciplines/bayesian-statistics/probabilidade-subjetiva-resumo.pdf).

Quando n√£o existe uma informa√ß√£o direta sobre $\theta$, uma alternativa √© usar a distribui√ß√£o marginal de $x$ dada por 
$$m(x) = \int_{\Theta} f(x|\theta) \pi(\theta) \, d\theta.$$
Por exemplo, se $\theta$ √© a produ√ß√£o di√°ria m√©dia de leite, informa√ß√£o sobre $\theta$ pode ser obtida a partir da informa√ß√£o que j√° temos sobre o rebanho, o que √© informa√ß√£o sobre a marginal de $x$.

### Prioris de entropia m√°xima

Assuma que temos $\mathbb{E}^{\pi}[g_k(\theta)] = \omega_k$ para $k=1,\dots, K$. Podemos selecionar $\pi$ que satisfa√ßa essas $K$ rela√ß√µes e maximize a entropia, que mede o n√≠vel de desordem em um sistema. Se $\Theta$ √© finito, temos que 
$$
\mathcal{E}(\pi) = \sum_{\theta_i \in \Theta} \pi(\theta_i) \log(\pi(\theta_i))
$$
√© a **entropia** de $\pi$. 
Essa quantidade √© uma medida de incerteza dada por $\pi$. 
Dessa forma, estamos minimizando a informa√ß√£o de $\pi$ trazida a priori. 
Sendo $\lambda_k$ o multiplicador de Lagrange associado a $\mathbb{E}^{\pi}[g_k(\theta)] = \omega_k$, temos que a defini√ß√£o da priori √© 
$$
\pi^*(\theta_i) \propto \exp\left\{\sum_{k=1}^K \lambda_k g_k(\theta_i)\right\}.
$$
No caso cont√≠nuo, as contas se complicam um pouco e precisamos de uma medida de refer√™ncia $\pi_0$,
que pode ser vista como a distribui√ß√£o a priori sem restri√ß√£o de momentos. 
Quando existe uma estrutura de grupo, a medida de Haar invariante √† direita √© a escolha natural para $\pi_0$. 
Nesse caso, a entropia √© definida como
$$
\mathcal{E}(\pi) = \int \log\left(\frac{\pi(\theta)}{\pi_0(\theta)}\right) \, \pi_0(d\theta),
$$
que √© a dist√¢ncia de Kullback-Leibler entre $\pi$ e $\pi_0$ e a distribui√ß√£o a priori que maximiza $\mathcal{E}$ √© 
$$
\pi^*(\theta) \propto \exp\left\{\sum_{k=1}^K \lambda_k g_k(\theta_i)\right\}\pi_0(\theta)
$$

### Aproxima√ß√µes param√©tricas

A forma mais utilizada √© provavelmente essa. Definimos uma fam√≠lia param√©trica para a distribui√ß√£o a priori e buscamos definir os par√¢metros atrav√©s dos momentos ou quartis da distribui√ß√£o. 
A base √© mais a tratabilidade matem√°tica do que a subjetividade. 
Outro ponto √© que distribui√ß√µes com caudas muito diferentes para $\Theta$ infinito levam a infer√™ncias bastante distintas.

## Prioris conjugadas

Prioris conjugadas s√£o baseadas na verossimilhan√ßa e, portanto, j√° definem a fam√≠lia param√©trica da distribui√ß√£o a priori, restando a defini√ß√£o dos par√¢metros. 
Isso limita a informa√ß√£o a priori que deve ser obtida a fim de definir uma distribui√ß√£o de probabilidade. 
Ela tamb√©m auxilia na computa√ß√£o, como veremos na defini√ß√£o:

**Fam√≠lia conjugada:** Uma fam√≠lia de distribui√ß√µes $\mathcal{F}$ sobre $\Theta$ √© conjugada para a verossimilhan√ßa $f(x|\theta)$ se para toda priori $\pi \in \mathcal{F}$, a posteriori $p(\cdot \mid x) \in \mathcal{F}$. 

Essa fam√≠lia se torna interessante quando ela √© a menor poss√≠vel (√© imposs√≠vel encontrar uma m√≠nima propriamente dita, mas a ideia √© que ela tenha dimens√£o de par√¢metros baixa) e parametrizada. Logo, atualizar a informa√ß√£o por $f(x|\theta)$ √© equivalente a atualizar os par√¢metros da distribui√ß√£o. 
Nas fam√≠lias conjugadas, podemos interpretar os hiperpar√¢metros como observa√ß√µes passadas virtuais, o que √© considerado um ponto positivo.

### Fam√≠lia exponencial e distribui√ß√µes conjugadas

Seja $\mu$ uma medida $\sigma$-finita em $\mathcal{X}$ e $\Theta$ o espa√ßo dos par√¢metros. 
Sejam $C : \mathcal{X} \to \mathbb{R}_+$, $h : \mathcal{X} \to \mathbb{R}_+$, $R : \Theta \to \mathbb{R}^k$ e $T : \mathcal{X} \to \mathbb{R}^k$ fun√ß√µes. A fam√≠lia de distribui√ß√µes com densidade com respeito a $\mu$
$$
f(x|\theta) = C(\theta) h(x) \exp\{R(\theta) \cdot T(x)\}
$$
√© chamada de **fam√≠lia exponencial** de dimens√£o $k$. Quando $R(\theta) = \theta$ e $T(x) = x$, a fam√≠lia √© dita **natural**.

> **Lema de Pitman‚ÄìKoopman**: Se uma fam√≠lia de distribui√ß√µes $f(\cdot | \theta)$ √© tal que para $n$ suficientemente grande, existe uma estat√≠stica suficiente de dimens√£o constante, ela √© exponencial se o suporte n√£o depende de $\theta$ (essa condi√ß√£o final exclui a distribui√ß√£o $U[-\theta, \theta]$, por exemplo). 

Al√©m disso, para toda amostra de $f$, existe uma estat√≠stica suficiente de dimens√£o constante.

O **espa√ßo natural** de par√¢metros √© denotado por 
$$
N = \left\{\theta \in \Theta \mid \int_{\mathcal{X}} e^{\theta\cdot x} h(x) \, d\mu(x) < +\infty \right\}.
$$
Ela √© regular se $N$ √© aberto e m√≠nimo se $dim(N) = dim(C(\mu)) = K$ em que $C(\mu)$ √© o menor conjunto convexo fechado que cont√©m o suporte de $\mu$.

Reescreva a densidade como 
$$
f(x|\theta) = h(x) e^{\theta \cdot x - \psi(\theta)},
$$
em que $\psi$ √© a **fun√ß√£o geradora cumulativa**, pois
$$
\mathbb{E}_{\theta}[X] = \nabla \psi(\theta), \operatorname{Cov}(X_i, X_j) = \psi_{\theta_i \theta_j}(\theta),
$$
supondo $\psi$ de classe $C^2$ e $\theta \in int(N)$.

**Priori conjugada:** Uma fam√≠lia conjugada para $f$ √© dada pela densidade
$$
\pi(\theta | \mu, \lambda) = K(\mu, \lambda) e^{\theta\cdot \mu - \lambda \psi(\theta)},
$$
cuja posteriori √© dada por $\pi(\theta | \mu + x, \lambda + 1)$. Se $\lambda > 0$ e $\mu/\lambda$ pertence ao interior de $C(\mu)$, $\pi$ define uma distribui√ß√£o de probabilidade [[Diaconis, Ylvisaker; 1978]](https://statweb.stanford.edu/~cgates/PERSI/papers/conjprior.pdf). Para uma tabela completa, consulte [aqui](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions).

Outro resultado verificado no artigo acima √© que a esperan√ßa a posteriori de $\theta$ √© dada por 
$$
\frac{\mu + n\bar{x}}{\lambda + n}, 
$$
quando $\mu \in \mathcal{X}$.

### Extens√µes

Considere o seguinte exemplo

---
``üìù`` **Exemplo [[Diaconis, Ylvisaker; 1985]](https://statistics.stanford.edu/technical-reports/quantifying-prior-opinion)**

Quando a moeda √© girada pela borda e observamos o resultado quando ela cai, temos um vi√©s maior para um lado do que para o outro devido a irregularidades. Seja $x \sim Binomial(n, p)$ o n√∫mero de caras nesse experimento ap√≥s $n$ jogadas. 
Como sabemos que existe uma irregularidade, poder√≠amos pensar em uma priori para $p$ que tivesse uma cara bimodal, dado peso para as duas possibilidades. Isso n√£o √© poss√≠vel com a fam√≠lia conjugada beta. 
Uma forma de fazer isso √©, portanto, atrav√©s de misturas de distribui√ß√µes beta.

---

Com esse exemplo, podemos ver que misturas de distribui√ß√µes conjugadas definem uma fam√≠lia conjugada maior que d√° maior flexibilidade para o formato de uma distribui√ß√£o a priori. 
Al√©m disso, podemos verificar que a mistura de distribui√ß√µes pode aproximar qualquer distribui√ß√£o a priori sob a [dist√¢ncia de Prokhorov](https://en.wikipedia.org/wiki/L%C3%A9vy%E2%80%93Prokhorov_metric).


## Distribui√ß√µes a priori n√£o informativas

Quando pouca (ou nenhuma) informa√ß√£o sobre $\theta$ est√° dispon√≠vel, √© dif√≠cil justificar a escolha com base subjetiva.
Nesse caso, uma alternativa √© usar a distribui√ß√£o dos dados para, a partir dela, definir uma distribui√ß√£o a priori.
Chamamos essas prioris de **n√£o informativas**. 
Mas devemos que lembrar que uma distribui√ß√£o ser n√£o informativa n√£o significa que ignor√¢ncia total est√° sendo representada probabilisticamente.
Elas podem ser usadas como prioris de refer√™ncia, todavia.

### Priori de Laplace

Laplace sugeriu construir a distribui√ß√£o a priori baseado no **Princ√≠pio da Raz√£o Insuficiente**, em que eventos elementares s√£o equiprov√°veis. 
Nesse caso, adotamos a priori uniforme.
Se o espa√ßo de par√¢metros n√£o for compacto, isso nos leva √† uma distribui√ß√£o impr√≥pria, por consequ√™ncia. 
Al√©m disso, se fizermos uma transforma√ß√£o biun√≠voca $\eta = g(\theta)$, a priori para $\eta$ n√£o ser√° uniforme pela F√≥rmula da Mudan√ßa de Vari√°veis, isto √©, a informa√ß√£o sobre $\theta$ n√£o foi criada a partir dessa transforma√ß√£o, mas a distribui√ß√£o n√£o √© uniforme.

### Prioris invariantes

O conceito de invari√¢ncia √© bem profundo na matem√°tica e, com base nesse conceito, podemos construir distribui√ß√µes invariantes a reparametriza√ß√£o. Por exemplo, a fam√≠lia $f(x - \theta)$ √© invariante √† transla√ß√£o, isto √©, $y = x - x_0$ tem distribui√ß√£o da mesma fam√≠lia para todo $x_0$, $f(x - (\theta - x_0))$. Chamamos $\theta$ de *par√¢metro de loca√ß√£o*.

### Priori de Jeffreys

A Priori de Jeffreys √© baseada na [Informa√ß√£o de Fisher](https://lucasmoschen.github.io/ta-sessions/infestatistica_BSc/FisherInformation/FisherInformation/) dada pela express√£o:
$$
I(\theta) = \mathbb{E}_{\theta}\left[\left(\frac{\partial \log f(X|\theta)}{\partial \theta}\right)^2\right],
$$
no caso unidimensional. A distribui√ß√£o de Jeffreys √© definida por 
$$
\pi^*(\theta) \propto I^{1/2}(\theta).
$$
Note que $I(\theta) = I(h(\theta))(h'(\theta))^2$ se $h$ √© uma transforma√ß√£o biun√≠voca. 
Nesse caso, $\pi^*(h(\theta)) \propto I^{1/2}(h(\theta)) = I^{1/2}(\theta)/|h'(\theta)|$, exatamente o que esper√°vamos usando a mudan√ßa de vari√°veis. 
Logo, essa priori √© invariante √† reparametriza√ß√£o.
Al√©m disso, $I(\theta)$ √© uma medida da quantidade de informa√ß√£o trazida pelo modelo sobre $\theta$.
Na pr√°tica, prioris de Jeffreys s√£o usualmente impr√≥prias.
No caso multidimensional, 
$$
\pi^*(\theta) \propto [det(I(\theta))]^{1/2}
$$
√© a priori de Jeffreys. 
Todavia, usar esse procedimento para construir prioris leva a paradoxos e incoer√™ncias.

**Observa√ß√£o:** A priori de Jeffreys para fam√≠lia de loca√ß√£o √© constante.

---
``üìù`` **Exemplo (caso normal)**

Suponha que $x \sim N(\mu, \sigma^2)$ com $\theta = (\mu, \sigma^2)$ desconhecido. Nesse caso, podemos calcular que 
$$
I(\theta) = \begin{bmatrix}
1/\sigma^2 & 0 \\ 0 & 2/\sigma^2
\end{bmatrix},
$$
e, portanto, $\pi(\theta) \propto 1/\sigma^2$. Se assumirmos que $\mu$ e $\sigma$ s√£o independentes a priori, todavia, teremos que $\pi(\mu, \sigma) = 1/\sigma$ como priori n√£o informativa e tamb√©m a medida de Haar invariante ao modelo loca√ß√£o-scala.

---

Essa priori, todavia, n√£o obedece ao Princ√≠pio da Verossimilhan√ßa, dado que a informa√ß√£o de Fisher de dois modelos diferentes podem ser diferentes, mesmo que as verossimilhan√ßas sejam proporcionais. [Confira essa resposta.](https://stats.stackexchange.com/questions/194448/do-you-have-to-adhere-to-the-likelihood-principle-to-be-a-bayesian).

### Prioris de refer√™ncia 

[[Bernardo; 1979]](https://people.eecs.berkeley.edu/~jordan/sail/readings/bernardo-1979.pdf) prop√¥s um procedimento para construir prioris n√£o informativas, ou como ele destaca, um procedimento para obter prioris de forma que a posteriori aproxime aquela que adviria de uma informa√ß√£o a priori vaga.
Seja $x \sim f(x | \theta)$ e $\theta = (\theta_1, \theta_2)$, em que $\theta_1$ √© o par√¢metro de interesse. A priori de refer√™ncia primeiro define $\pi(\theta_2 | \theta_1)$ usando a priori de Jeffreys atrav√©s $f(x|\theta)$ quando $\theta_1$ √© fixado. 
Depois, ele calcula 
$$
\tilde{f}(x|\theta_1) = \int f(x|\theta) \pi(\theta_2|\theta_1) \, d\theta_2
$$
e calcula a priori de Jeffreys para $\theta_1$ baseando-se em $\tilde{f}$. 
Assim, o processo elimina os par√¢metros que n√£o s√£o de interesse.
O algoritmo se generaliza para mais camadas de par√¢metros.

### Prioris matching 

Uma forma, no m√≠nimo curiosa, de construir prioris n√£o informativas √© baseada em propriedades frequentistas, isto √©, em que propriedades funcionem em m√©dia considerando $x$.
Seja $C_x$ um conjunto de confian√ßa a posteriori n√≠vel $\alpha$, isto √©, 
$$
p(g(\theta) \in C_x | x) = 1-\alpha.
$$
Esse conjunto define tem cobertura frequentista $\Pr_{\theta}(g(\theta) \in C_x)$, em que nesse caso $C_x$ √© a vari√°vel aleat√≥ria. 
Em geral, quando $C_x = (-\infty, k_{\alpha}(x))$, ent√£o $\Pr_{\theta}(\theta \le k_{\alpha}(x)) = 1 - \alpha + O(n^{-1/2})$. No caso da priori de Jeffreys, isso se torna $O(n^{-1})$ que decresce mais rapidamente. 
Para mais detalhes, [consulte esse link](https://projecteuclid.org/ebook/Download?urlid=10.1214/lnms/1215091929&isFullBook=false).

## Pontua√ß√µes finais

- Informa√ß√£o a priori n√£o consegue ser traduzida em uma distribui√ß√£o de probabilidade √∫nica. Al√©m disso, ela √© bastante complicada, principalmente em se tratando de definir caudas de forma subjetiva. 

- Se alguma informa√ß√£o √© dispon√≠vel, us√°-la favorece infer√™ncias quando comparado a abordagens n√£o informativas.

- An√°lise de sensibilidade √© um t√≥pico importante, que verifica a influ√™ncia da escolha da priori nas infer√™ncias. Para essa an√°lise, assumimos que a priori $\pi$ mora em alguma classe de distribui√ß√µes, que mensura a incerteza sobre $\pi$. Essas classes podem ser: (i) prioris conjugadas: convenientes matematicamente; (ii) momentos definidos: a classe de distribui√ß√µes que tem determinados momentos limitados imp√µe condi√ß√µes fortes sobre a cauda e inclui muitas distribui√ß√µes imposs√≠veis; (iii) classes de vizinhan√ßa: pondera por um $\epsilon$ uma outra classe de distribui√ß√µes $Q$ a ser escolhida; entre outras.