# Intervalos de Confian√ßa 

Esse tema procura responder qu√£o confiantes estamos de um estimador. 
√â claro que essa pergunta tem que ser melhor descrita matematicamente. 
De forma geral, estamos procurando por uma estat√≠stica $C(X)$ em que para cada $X=x$ observado, $C(x)$ √© um conjunto. 
Mas na pr√°tica, procuramos por estat√≠sticas $(A(X), B(X))$ que nos deem confian√ßa de que contenham o par√¢metro verdadeiro, isto √©. 

> O intervalo $[a,b]$, uma realiza√ß√£o de $[A(X),B(X)]$, tem 95% de confian√ßa se em 95% do tempo, o par√¢metro procurado est√° entre $a$ e $b$. 
> Veja que a ideia √© frequentista, dado que a interpreta√ß√£o est√° ligada √† frequ√™ncia de pertencimento quando o n√∫mero de experimentos tende para infinito.
> (Cuidado: N√£o vamos falar da probabilidade do par√¢metro estar em $[a,b]$, isso n√£o faz sentido, pois $\theta$ n√£o √© uma vari√°vel aleat√≥ria, e sim um valor fixo).

## Defini√ß√£o 

Sejam $X_1, ..., X_n \overset{iid}{\sim} F(\theta)$.
Uma **estimador intervalar** de $\theta$ √© um par de estat√≠sticas $(A(X), B(X))$, tal que $\mathbb{P}(A(X) \le B(X)) = 1$
Se $X=x$ √© observado, ent√£o $(A(x), B(x))$ √© uma estimativa intervalar.
Para um estimador intervalar, a **probabilidade de cobertura** √© 
$$
\mathbb{P}_{\theta}(\theta \in [A(X), B(X)]) = \mathbb{P}_{\theta}(A(X) \le \theta, B(X) \ge \theta).
$$
Um **intervalo de confian√ßa** com coeficiente de confian√ßa $\gamma$ √© um estimador intervalar que satisfaz 
$$
\inf_{\theta} \mathbb{P}_{\theta}(\theta \in [A(X), B(X)]) = \gamma, 
$$
ou tamb√©m, $\mathbb{P}(A(X) < \theta < B(X)) \ge \gamma$, isto √©, a probabilidade de cobertura √© no m√≠nimo $\gamma$.
Ap√≥s observarmos os valores de $X_1, ..., X_n$ e computarmos $A = a$ e $B = b$, o intervalo $(a,b)$ √© chamado de valor observado do intervalo de confian√ßa. 

### Intervalo de Confian√ßa para a m√©dia de $N(\mu, \sigma^2)$

Seja $X_1, ..., X_n \sim N(\mu, \sigma^2)$. Para cada $0 < \gamma < 1$, o intervalo $(A,B)$ √© intervalo de confian√ßa exato para $\mu$ com coeficiente $\gamma$, em que:

$$
A = \bar{X}_n - T_{n-1}^{-1}\left(\frac{1 + \gamma}{2}\right)\frac{\sigma '}{n^{1/2}}
$$
$$
B = \bar{X}_n + T_{n-1}^{-1}\left(\frac{1 + \gamma}{2}\right)\frac{\sigma '}{n^{1/2}}
$$

onde $T_{n-1}$ denota a cdf da distribui√ß√£o $t$ com $n-1$ graus de liberdade. 

Esse resultado implica do fato de que a distribui√ß√£o de $U = \frac{n^{1/2}(\bar{X}_n - \mu)}{\sigma '}$ √© conhecida por distribui√ß√£o $t$ com $n-1$ graus de liberdade e fazemos
$$\gamma = P(-c < U < c) = P(A < \mu < B)$$ 
coo $c$ sendo escolhido de acordo com $\gamma$.

### Implementa√ß√£o 

Considere dados sobre pesos de beb√™s logo ao nascer. 

1. bwt: peso do beb√™ ao nascer. 
2. gestation: dura√ß√£o em dias da gesta√ß√£o. 
3. parity: primeiro filho ou n√£o.
4. age: idade da m√£e. 
5. height: altura da m√£e em polegadas. 
6. weight: peso da m√£e em pounds.  
7. smoke: se a m√£e √© fumante ou n√£o. 

```python
# Importando bibliotecas 
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import t
```

```python
birth_df = pd.read_csv("http://people.reed.edu/~jones/141/Bwt.dat")
birth_df.head()
```
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bwt</th>
      <th>gestation</th>
      <th>parity</th>
      <th>age</th>
      <th>height</th>
      <th>weight</th>
      <th>smoke</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>120</td>
      <td>284</td>
      <td>0</td>
      <td>27</td>
      <td>62</td>
      <td>100</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>113</td>
      <td>282</td>
      <td>0</td>
      <td>33</td>
      <td>64</td>
      <td>135</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>128</td>
      <td>279</td>
      <td>0</td>
      <td>28</td>
      <td>64</td>
      <td>115</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>108</td>
      <td>282</td>
      <td>0</td>
      <td>23</td>
      <td>67</td>
      <td>125</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>136</td>
      <td>286</td>
      <td>0</td>
      <td>25</td>
      <td>62</td>
      <td>93</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
sns.histplot(data = birth_df.bwt, kde = True)
plt.title('Histograma dos pesos dos beb√™s')
plt.show()
birth_df[birth_df.smoke == 0].bwt.hist(density = True, label = 'N√£o fumante')
birth_df[birth_df.smoke == 1].bwt.hist(density = True, label = 'Fumante', alpha = 0.6)
plt.xlabel('Peso')
plt.legend()
plt.show()
```

![png](output_4_0.png)

![png](output_4_1.png)

Sabemos que essa √© uma extra√ß√£o de uma popula√ß√£o maior. Para conseguirmos mais amostras, vamos usar um procedimento chamado **bootstrap**. 
A ideia desse procedimento √© criar um novas amostras a partir de uma amostra inicial, usando `replace = True` como diferencial. 
Vou fazer esse procedimento diversas vezes e ir calculando a m√©dia amostral. 
Como a m√©dia amostral √© uma vari√°vel aleat√≥ria, vamos obter um histograma das realiza√ß√µes. 

Vamos supor que o peso $W_i$ da crian√ßa $i$ vem de uma distribui√ß√£o com par√¢metros $\mu$ e $\sigma^2$ desconhecidos. 
Nesse caso, $\bar{W}_i$ vir√° de uma distribui√ß√£o normal com par√¢metros $\mu$ e $\sigma^2/n$. 

```python
ite = 10000
n = 200

bootstrap_means = np.zeros(ite)
for i in range(ite):
    bootstrap_sample = birth_df.sample(n = n, replace = True, random_state=i)
    bootstrap_means[i] = bootstrap_sample.bwt.mean()
```

```python
sns.histplot(bootstrap_means, kde = True)
plt.title("M√©dias das amostras")
plt.xlabel('Peso')
plt.show()
```

![png](output_7_0.png)

Vamos calcular o nosso intervalo de confian√ßa com $\gamma = 0.95$. Temos que:

```python
gamma = 0.95

A = lambda x: np.mean(x) - t.ppf(q = (1 + gamma)/2, df = len(x) - 1)*np.std(x, ddof = 1)/len(x)**(1/2)
B = lambda x: np.mean(x) + t.ppf(q = (1 + gamma)/2, df = len(x) - 1)*np.std(x, ddof = 1)/len(x)**(1/2)
```

```python
ite = 100
n = 500

bootstrap_intervals  = np.zeros((ite,2))
for i in range(ite):
    bootstrap_sample = birth_df.sample(n = n, replace = True, random_state=i)
    bootstrap_intervals[i,0] = A(bootstrap_sample.bwt)
    bootstrap_intervals[i,1] = B(bootstrap_sample.bwt)
    
out_values = np.where((bootstrap_intervals[:,0] > 119.5) | (bootstrap_intervals[:,1] < 119.5))
```


```python
plt.figure(figsize = (6,10))
plt.scatter(bootstrap_intervals[:,0], np.arange(0,ite), color = 'red', label = 'a')
plt.scatter(bootstrap_intervals[:,1], np.arange(0,ite), color = 'green', label = 'b')
plt.scatter(bootstrap_intervals[out_values[0],0], out_values[0], color = 'black', label = 'Fora')
plt.scatter(bootstrap_intervals[out_values[0],1], out_values[0], color = 'black')
plt.vlines(119.5, ymin = 0, ymax = ite, linestyle = '--', alpha = 0.6, label = 'M√©dia real')
plt.legend()
plt.show()
```

![png](output_11_0.png)

### Interpreta√ß√£o 

Estamos fazendo uma afirma√ß√£o probabil√≠stica sobre o intervalo $(A,B)$ antes de observar os dados. 
Ap√≥s observarmos os dados, n√£o podemos interpretar $(a,b)$ como um intervalo em que temos 95% de confian√ßa de $g(\theta)$ estar no intervalo. 
Antes de observarmos as amostras, temos a confian√ßa de que 95% dos intervalos conter√£o $\mu$.
Sabemos que a realiza√ß√£o infinita desse experimento faz com que 95% dos intervalos realizados contenham o valor verdadeiro.

### Sem simetria

Constru√≠mos anteriormente um intervalo sim√©trico, onde a estat√≠stica $U$ acima mencionada estaria entre $-c$ e $c$ com probabilidade $\gamma$. 
Mas podemos desenvolver intervalos n√£o sim√©tricos tamb√©m. 
Uma forma que podemos fazer isso √© escolhendo $\gamma_1$ e $\gamma_2$, tal que $\gamma_2 - \gamma_1 = \gamma$. 
Assim: 

$$P\left(T_{n-1}^{-1}(\gamma_1) < U < T_{n-1}^{-1}(\gamma_2)\right) = \gamma$$

Talvez vc esteja se perguntando: porque escolher $\gamma_1, \gamma_2$ dessa forma? Bom: 

$$
\begin{split}
\gamma &= P\left(T_{n-1}^{-1}(\gamma_1) < U < T_{n-1}^{-1}(\gamma_2)\right) \\
&= P\left(U < T_{n-1}^{-1}(\gamma_2)\right) - P\left(U \leq T_{n-1}^{-1}(\gamma_1)\right) \\
&= \gamma_2 - \gamma_1
\end{split}
$$ 

### Intervalo unilateral para a m√©dia de $N(\mu,\sigma^2)$

Nas mesma condi√ß√µes do teorema anterior, mas as estat√≠sticas para baixo e para cima com coeficiente $\gamma$ para $\mu$ s√£o: 

$$
A = \bar{X}_n - T_{n-1}^{-1}\left(\gamma\right)\frac{\sigma '}{n^{1/2}}
$$
$$
B = \bar{X}_n + T_{n-1}^{-1}\left(\gamma\right)\frac{\sigma '}{n^{1/2}}
$$

## Quantidades Pivotais 

Uma vari√°vel aleat√≥ria $V(\vec{X}, \theta)$ √© uma **quantidade pivotal** se sua distribui√ß√£o independe de $\theta$.
Assim, se $X_1, ..., X_n \overset{idd}{\sim} F(\theta)$, ent√£o $V(\vec{X}, \theta)$ tem a mesma distribui√ß√£o para todo $\theta$.

---
``üìù`` **Exemplo da Gamma**

Sejam $X_1, \dots, X_n \overset{iid}{\sim} Gamma(a, \lambda)$, com $a$ conhecido.
Assim, $T = \sum_{i=1}^n X_i \sim Gamma(na, \lambda)$.
Temos que 
$$
V(X, \lambda) = \lambda T \sim \gamma(na, 1),
$$
que n√£o depende de $\lambda$.
Com isso, $V$ √© uma quantidade pivotal.

---

Uma forma de procurar por quantidades pivotais √© olhando a pdf da distribui√ß√£o. 
No caso da Gamma, por exemplo, temos que
$$
f_T(t) = \frac{\lambda^{na}}{\Gamma(na)} t^{an-1}e^{-t/\lambda},
$$
portanto, $v = t/\lambda$, faz com que a densidade n√£o depende de $\lambda$.
Portanto, multiplicar $t$ por $\lambda$ √© suficiente.

De forma geral, se a densidade de $T$ √© da forma
$$
f(t|\theta) = g(V(t,\theta)) \bigg|\frac{\partial}{\partial t} V(t,\theta)\bigg|,
$$
para alguma fun√ß√£o $g$ e $V$ uma fun√ß√£o mon√≥tona em $t$.
Veja que isso est√° relacionado com o Teorema da Mudan√ßa de Vari√°vel.

Dada uma quantidade pivotal $V$, ent√£o 
$$
C(X) = \{\theta : a \le V(x,\theta) \le b\}
$$
√© intervalo de confian√ßa com coeficiente $\gamma$ se $\mathbb{P}_{\theta}(a \le V(x,\theta) \le b) \ge \gamma$.

**Teorema:** Sejam $X_1, ..., X_n \overset{idd}{\sim} F(\theta)$. 
Suponha que 

1. Exista $V$ pivotal. 
2. A cdf $G$ de $V$ √© cont√≠nua. 
3. Exista fun√ß√£o $r$ tal $r(V(X,\theta), X) = g(\theta)$, ou seja, √© uma esp√©cie de "inversa". 
4. $r(v,x)$ (3) √© uma fun√ß√£o estritamente crescente em $v$ para todo $x$. 

Ent√£o 

$$
A = r(G^{-1}(\gamma_1), X)
$$
$$
B = r(G^{-1}(\gamma_2), X)
$$

s√£o os pontos extremos do intervalo de confian√ßa exato para $g(\theta)$ de coeficiente $\gamma = \gamma_2 - \gamma_1$. Se $r$ √© estritamente decrescente, invertemos $A$ e $B$. 

## Exemplo com Regress√£o Linear

O dataset que utilizei anteriormente n√£o √© muito bom para esse exemplo, mas eu vou usar, de qualquer forma, para entendermos o processo e como pode nos ajudar o intervalo de confian√ßa. 

Em uma Regress√£o Linear, queremos dizer aferir uma rela√ß√£o linear entre duas vari√°veis, isto √©, queremos dizer que uma vari√°vel pode ser obtida pela outra atrav√©s de uma reta, mais um erro aleat√≥rio. Suponha que queremos estimar $Y$ o peso da crian√ßa ao nascer, sabendo a informa√ß√£o do tempo de gesta√ß√£o $X$ e que 

$$
Y = aX + b + E,
$$

onde $E \sim N(0,\sigma^2)$. Nesse caso, estamos dizendo que $Y|X \sim N(aX + b, \sigma^2)$. Queremos estimar $a$ e $b$ de forma que tenhamos o melhor ajuste poss√≠vel. Esse tema em espec√≠fico n√£o me interessa. Entretanto, podemos dizer que queremos estimar $aX + b$, a m√©dia de uma normal, mas que muda para cada $X = x$ observado. 


```python
sns.lmplot(x = 'gestation', y = 'bwt', data = birth_df, height = 5, ci = 95)
```

![png](output_16_1.png)

O resultado n√£o foi muito bom (na verdade eu j√° imaginava isso). 
Mas o interessante √© tentar refletir o que essas bandas significam? 
Por que os pontos n√£o est√£o nela? 
Esper√°vamos que estivesse? 
E por que ela diminui a vari√¢ncia com o n√∫mero de pontos? 

Essas perguntas v√£o ser devidamente respondidas no pr√≥ximo curso de Modelagem Estat√≠stica!

Mas eu j√° vou adiantando que esse intervalo de confian√ßa √© para a m√©dia estimada. 

## Intervalos de confian√ßa assint√≥ticos

Sejam $X_1, \dots, X_n \overset{iid}{\sim} F(\theta)$ e $\hat{\theta}_n$ o MLE correspondente.
Assim, supondo as condi√ß√µes de regularidade de Fisher, temos que 
$$
\sqrt{n}(\hat{\theta}_n - \theta) \to N(0, 1/I(\theta)).
$$
Com isso, $\sqrt{n I(\theta)}(\hat{\theta}_n - \theta)$ √© uma quantidade **aproximadamente pivotal**.
Com isso, defina
$$
S = \{\theta :\sqrt{n I(\theta)}|\hat{\theta}_n - \theta| < z_{\alpha/2}\},
$$
em que $z_{\alpha} = \Phi^{-1}(1-\alpha)$ e o quantile $1-\alpha$ da normal padr√£o.
Portanto, 
$$
\mathbb{P}_{\theta}(\theta \in S) \to 1-\alpha,
$$
quando $n \to \infty$.

O conjunto $S$ n√£o √©, todavia, um intervalo necessariamente.
Al√©m do mais, $I(\theta)$ pode ser dif√≠cil de se obter.
Na pratica, calcula-se $I(\hat{\theta})$ e se usa que $I(\hat{\theta}_n)/I(\theta) \to 1$.
Com isso, o intervalo 
$$
\left(\hat{\theta}_n - \frac{z_{\alpha/2}}{\sqrt{n I(\hat{\theta}_n)}},  \hat{\theta}_n + \frac{z_{\alpha/2}}{\sqrt{n I(\hat{\theta}_n)}}\right)
$$
√© assintoticamente um intervalo de confian√ßa $1-\alpha$.