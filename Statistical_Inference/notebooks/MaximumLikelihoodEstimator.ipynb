{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimador de Máxima Verossimilhança\n",
    "\n",
    "## Introdução \n",
    "\n",
    "\"Tradicionalmente a inferência estatística sobre a média de uma população se apoia no Teorema Central do Limite para construir Intervalos de Confiança ou testar hipóteses sobre o valor do parâmetro. Esta abordagem da estatística tradicional pode ser extendida para inferências a respeito de qualquer parâmetro, não só a média. Da mesma forma que no caso da média populacional se usa a distribuição *t-Student* ou a distribuição *Normal Padrão*, no caso de outros parâmetros se  utiliza outras distribuições amostrais. Essas distribuições são **chamadas amostrais porque representam o comportamento das estimativas baseado na repetição\n",
    "incontável do processo de amostragem**.\n",
    "\n",
    "Na prática científica, no entanto, sempre se realiza uma **única amostragem**, o\n",
    "que resulta em uma única amostra. Assim, o conceito de distribuição amostral\n",
    "é até certo ponto artificial, pois em pesquisa científica **não raciocinamos em termos de repetições incontáveis de experimentos ou processos de observação**. O\n",
    "resultado disto é que o conceito de teste estatístico de hipótese e de intervalo de confiança são frequentemente mal compreendidos. \n",
    "\n",
    "O desenvolvimento da inferência estatística a partir do **conceito de verossimilhança tem sido utilizado como uma alternativa à abordagem estatística frequentista e, segundo alguns autores (como por exemplo Royall, 1997), é mais coerente\n",
    "com a prática científica**.\" (Batista, 2009)\n",
    "\n",
    "[Site de Referência](http://cmq.esalq.usp.br/BIE5781/lib/exe/fetch.php?media=leituras:verossim.pdf)\n",
    "\n",
    "## Função Verossimilhança\n",
    "\n",
    "Quando a função de densidade de probabilidade $f_n(x|\\theta)$ das observações de uma amostra aleatória é vista como uma função de $\\theta$, chamamos ela de função de verossimilhança.\n",
    "\n",
    "$$\n",
    "\\theta \\mapsto f_n(x|\\theta) := L(\\theta|x)\n",
    "$$\n",
    "\n",
    "## Estimador de Máxima Verossimilhança (MLE)\n",
    "\n",
    "Para cada observação $x$, seja $\\delta(x)$ um valor de $\\theta \\in \\Omega$ tal que a função de verossimilhnaça seja **máxima**. Defina $\\hat{\\theta} = \\delta(X)$ o estimador. \n",
    "\n",
    "É importante observar que o máximo dessa função pode não estar em um ponto de $\\Omega$. Nesse caso, MLE não existe. Ele pode não estar unicamente definido, também. \n",
    "\n",
    "## Limitações \n",
    "\n",
    "- Não existência em todos os casos, isso depende muito da função e do espaço dos parâmetros. \n",
    "- Não unicidade em todos os casos.\n",
    "- Não podemos interpretar MLE como o parâmetro mais provável, pois teríamos que ter um espaço de probabilidade associado ao parâmetro, o que não é dado. \n",
    "\n",
    "## Propriedades \n",
    "\n",
    "### Invariância \n",
    "\n",
    "Se $\\hat{\\theta}$ é o estimador de máxima verossimilhança de $\\theta$ e $g$ é uma função injetiva, então $g(\\hat{\\theta})$ é o estimador de máxima verossimilhança de $g(\\theta)$. Na verdade, podemos retirar condição de injetividade.  \n",
    "\n",
    "#### MLE de uma Função\n",
    "\n",
    "### Consistência\n",
    "\n",
    "Suponha que \n",
    "\n",
    "### Método dos Momentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
